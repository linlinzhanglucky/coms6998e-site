<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>COMS6998E Portfolio ‚Äì Linlin Zhang</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background: #f9f9f9;
    }
    header {
      background-color: #1e2d50;
      color: white;
      padding: 1rem;
      text-align: center;
    }
    nav {
      display: flex;
      justify-content: center;
      background-color: #32456b;
    }
    nav a {
      color: white;
      padding: 1rem;
      text-decoration: none;
    }
    nav a:hover {
      background-color: #465f91;
    }
    .container {
      max-width: 900px;
      margin: 2rem auto;
      padding: 1.5rem;
      background-color: white;
      border-radius: 10px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    .review {
      margin-bottom: 2.5rem;
    }
    .badge {
      display: inline-block;
      background-color: #ffd700;
      color: black;
      padding: 0.2rem 0.6rem;
      margin-left: 0.5rem;
      font-size: 0.8rem;
      border-radius: 5px;
    }
    .link-button {
      margin: 1rem 0;
      display: inline-block;
      background-color: #2c5cc5;
      color: white;
      padding: 0.5rem 1rem;
      border-radius: 6px;
      text-decoration: none;
      font-weight: bold;
    }
    .link-button:hover {
      background-color: #1e3e99;
    }
  </style>
</head>
<body>
  <header>
    <h1>Linlin Zhang ‚Äì COMS6998E: Robot Learning Portfolio</h1>
    <p>Critical reviews, reflections, and final deliverables from Spring 2025</p>
  </header>

  <nav>
    <a href="#reviews">Paper Reviews</a>
    <a href="review_index_data.html">All Reviews</a>
    <a href="#project">Course Project</a>
    <a href="#presentation">Presentation</a>
    <a href="#insights">Insights</a>
  </nav>

  <div class="container" id="reviews">
    <h2>üìù Paper Reviews</h2>

    <p>
      üëâ <a class="link-button" href="review_index_data.html">View Full Review List</a>
    </p>

    <div class="review">
      <h3>1. HumanPlus: Humanoid Shadowing and Imitation from Humans <span class="badge">‚úÖ Submitted</span></h3>
      <p><strong>Main Contribution:</strong><br>
      Proposes a system that combines real-time human teleoperation and offline imitation learning to train humanoid robots to perform natural movements and autonomous tasks.</p>
      <p><strong>Limitations & Failure Cases:</strong><br>
      The system struggles to generalize to tasks with significantly different dynamics. It is also limited in environments with occlusions or inconsistent pose estimation due to reliance on vision alone.</p>
      <p><strong>Suggested Improvements:</strong><br>
      Integrating multimodal sensing (e.g., depth or tactile feedback) and incorporating fine-tuned large foundation models could improve generalization and robustness.</p>
    </div>

    <div class="review">
      <h3>2. RoboTAP: Learning to Interact via Contact Under Sparse Tactile Supervision <span class="badge">‚ú® Extra Review</span></h3>
      <p><strong>Main Contribution:</strong><br>
      Introduces a method that leverages sparse tactile signals to guide contact-rich interactions, enabling manipulation tasks with limited visual input.</p>
      <p><strong>Limitations & Failure Cases:</strong><br>
      Shows reduced performance when applied to deformable or dynamic objects. It also depends heavily on the tactile sensor‚Äôs precision, which may not generalize across hardware.</p>
      <p><strong>Suggested Improvements:</strong><br>
      Augmenting the training with synthetic tactile data and integrating proprioceptive signals could enhance adaptability and policy stability.</p>
    </div>

    <!-- Add additional review entries here -->
  </div>

  <div class="container" id="project">
    <h2>üìÇ Final Course Project</h2>
    <p><strong>Title:</strong> Tactile-Based Online Active Shape Exploration and Reconstruction</p>
    <p><strong>Summary:</strong><br>
    We developed an RL-based framework where a UR5e robot, equipped with a GelSlim 3.0 sensor, learns to explore and reconstruct the shape of unseen 3D objects using sparse tactile feedback. The policy is trained to maximize surface coverage efficiently by leveraging a PointNet-based representation.</p>
    <p><strong>Repository:</strong> <a href="https://github.com/linlinzhanglab/tactile-rl" target="_blank">GitHub ‚Äì tactile-rl</a></p>
  </div>

  <div class="container" id="presentation">
    <h2>üé§ Paper Presentation</h2>
    <p><strong>Presented Paper:</strong> HumanPlus: Humanoid Shadowing and Imitation from Humans</p>
    <p><strong>Slides:</strong> <em>(Add your link here)</em></p>
  </div>

  <div class="container" id="insights">
    <h2>üí° Insights & Participation</h2>

    <h3>üìç Unitree Robotics Talk ‚Äì May 9, 2025</h3>
    <p>I attended the live demo and presentation of Unitree‚Äôs Go2 and G1 robots. The talk emphasized the role of robust physical systems and large foundation models in realizing general-purpose embodied AI. This deepened my understanding of how real-world hardware integrates with foundational research.</p>

    <h3>üí¨ Ed Discussion Contributions</h3>
    <ul>
      <li>Clarified the architecture used in RoboTAP (received 3 upvotes)</li>
      <li>Asked about fusing tactile input with foundation models for more stable policies</li>
    </ul>

    <h3>üß† Final Reflection</h3>
    <p>This course significantly enriched my understanding of robot learning. I submitted more than the required number of paper reviews and actively contributed to Ed discussions to make up for limited in-class participation. The process of reviewing diverse papers and presenting gave me a well-rounded view of both foundational and cutting-edge robotics research.</p>
  </div>
</body>
</html>
